{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b8ff514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (80.3.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.70.0)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.11.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.1.3)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.14.0-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Using cached optree-0.17.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/376.0 MB 9.5 MB/s eta 0:00:40\n",
      "    --------------------------------------- 5.0/376.0 MB 14.4 MB/s eta 0:00:26\n",
      "    --------------------------------------- 8.4/376.0 MB 14.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 12.3/376.0 MB 16.4 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 15.2/376.0 MB 15.4 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 17.8/376.0 MB 15.2 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 20.4/376.0 MB 14.3 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 25.4/376.0 MB 15.6 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 30.4/376.0 MB 16.5 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 35.9/376.0 MB 17.4 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 40.9/376.0 MB 18.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 46.1/376.0 MB 18.6 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 51.4/376.0 MB 19.0 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 57.7/376.0 MB 19.7 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 62.1/376.0 MB 20.0 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 68.4/376.0 MB 20.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 73.7/376.0 MB 20.6 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 78.9/376.0 MB 20.9 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 82.8/376.0 MB 21.0 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 87.0/376.0 MB 20.7 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 91.2/376.0 MB 20.6 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 96.2/376.0 MB 20.7 MB/s eta 0:00:14\n",
      "   ---------- ---------------------------- 100.7/376.0 MB 20.5 MB/s eta 0:00:14\n",
      "   ---------- ---------------------------- 102.8/376.0 MB 20.0 MB/s eta 0:00:14\n",
      "   ----------- --------------------------- 107.7/376.0 MB 20.2 MB/s eta 0:00:14\n",
      "   ----------- --------------------------- 112.7/376.0 MB 20.3 MB/s eta 0:00:13\n",
      "   ------------ -------------------------- 116.1/376.0 MB 20.1 MB/s eta 0:00:13\n",
      "   ------------ -------------------------- 121.6/376.0 MB 20.4 MB/s eta 0:00:13\n",
      "   ------------- ------------------------- 127.4/376.0 MB 20.5 MB/s eta 0:00:13\n",
      "   ------------- ------------------------- 130.5/376.0 MB 20.3 MB/s eta 0:00:13\n",
      "   ------------- ------------------------- 134.5/376.0 MB 20.3 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 138.1/376.0 MB 20.1 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 142.6/376.0 MB 20.1 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 146.3/376.0 MB 20.1 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 149.4/376.0 MB 19.9 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 152.3/376.0 MB 19.9 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 155.7/376.0 MB 19.8 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 159.6/376.0 MB 19.6 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 161.5/376.0 MB 19.4 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 167.5/376.0 MB 19.5 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 172.0/376.0 MB 19.5 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 175.9/376.0 MB 19.5 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 182.2/376.0 MB 19.7 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 185.9/376.0 MB 19.7 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 189.0/376.0 MB 19.6 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 193.7/376.0 MB 19.6 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 197.9/376.0 MB 19.6 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 201.6/376.0 MB 19.6 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 204.7/376.0 MB 19.5 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 208.7/376.0 MB 19.4 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 212.6/376.0 MB 19.4 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 217.6/376.0 MB 19.4 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 222.6/376.0 MB 19.5 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 226.0/376.0 MB 19.4 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 228.3/376.0 MB 19.4 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 231.5/376.0 MB 19.3 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 234.1/376.0 MB 19.1 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 237.8/376.0 MB 19.1 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 243.0/376.0 MB 19.1 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 246.7/376.0 MB 19.1 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 248.3/376.0 MB 19.0 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 253.0/376.0 MB 19.0 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 255.6/376.0 MB 18.9 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 259.5/376.0 MB 18.8 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 263.5/376.0 MB 18.9 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 268.2/376.0 MB 19.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 271.3/376.0 MB 19.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 276.6/376.0 MB 19.2 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 278.9/376.0 MB 19.1 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 282.6/376.0 MB 19.2 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 286.3/376.0 MB 19.1 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 288.4/376.0 MB 19.1 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 292.8/376.0 MB 18.9 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 295.2/376.0 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 298.1/376.0 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 300.9/376.0 MB 18.5 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 303.3/376.0 MB 18.5 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 306.4/376.0 MB 18.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 310.9/376.0 MB 18.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 313.8/376.0 MB 18.0 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 317.2/376.0 MB 17.9 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 321.9/376.0 MB 17.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 326.1/376.0 MB 17.8 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 329.3/376.0 MB 17.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 335.5/376.0 MB 17.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 339.5/376.0 MB 17.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 343.7/376.0 MB 17.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 349.2/376.0 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 352.1/376.0 MB 17.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 355.7/376.0 MB 17.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 359.7/376.0 MB 17.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 363.3/376.0 MB 17.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  367.8/376.0 MB 17.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  371.2/376.0 MB 17.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  374.3/376.0 MB 17.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 376.0/376.0 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.8/2.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading keras-3.11.1-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 71.6 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 18.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 7.1/26.4 MB 16.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 11.0/26.4 MB 18.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 16.0/26.4 MB 18.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 19.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.6/26.4 MB 18.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 17.1 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 3.7/5.5 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 16.8 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-win_amd64.whl (314 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 8.8 MB/s eta 0:00:00\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, pygments, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, google-pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 h5py-3.14.0 keras-3.11.1 libclang-18.1.1 markdown-3.8.2 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.3 namex-0.1.0 opt-einsum-3.4.0 optree-0.17.0 pygments-2.19.2 rich-14.1.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wheel.exe is installed in 'C:\\Users\\shrey\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pygmentize.exe is installed in 'C:\\Users\\shrey\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\shrey\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\shrey\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'C:\\Users\\shrey\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe and toco.exe are installed in 'C:\\Users\\shrey\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: C:\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df864ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, LabelEncoder\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for neural network implementation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fuel consumption dataset\n",
    "df = pd.read_csv('Fuel_Consumption_2000-2022.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8df596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical summary of numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation matrix of numerical features\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c38f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fuel efficiency categories for classification (low, medium, high efficiency)\n",
    "df['FUEL_EFFICIENCY'] = pd.cut(df['FUEL CONSUMPTION'], \n",
    "                              bins=[0, 8, 12, float('inf')], \n",
    "                              labels=['High', 'Medium', 'Low'])\n",
    "df['FUEL_EFFICIENCY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec80ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare independent variables (features)\n",
    "feature_columns = ['YEAR', 'ENGINE SIZE', 'CYLINDERS', 'HWY (L/100 km)', 'COMB (L/100 km)', 'EMISSIONS']\n",
    "X = df[feature_columns].copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dependent variable (target)\n",
    "y = df['FUEL_EFFICIENCY'].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd2002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a00341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(f\"Scaled training features shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled testing features shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Artificial Neural Network with 2 hidden layers of 6 neurons each\n",
    "model = Sequential()\n",
    "\n",
    "# First hidden layer with 6 neurons and ReLU activation\n",
    "model.add(Dense(6, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "\n",
    "# Second hidden layer with 6 neurons and tanh activation\n",
    "model.add(Dense(6, activation='tanh'))\n",
    "\n",
    "# Output layer with 3 neurons for 3 classes and softmax activation\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b05000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the neural network with Adam optimizer, categorical crossentropy loss and accuracy metric\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c4d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the neural network with batch_size=32 and epochs=100\n",
    "history = model.fit(X_train_scaled, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=100, \n",
    "                    validation_data=(X_test_scaled, y_test), \n",
    "                    verbose=0)\n",
    "\n",
    "print(\"Neural network training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66faa39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model performance on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test_scaled, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history (accuracy and loss)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(history.history['loss'], label='Training Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative model with different activation functions (ReLU, Sigmoid)\n",
    "model2 = Sequential()\n",
    "\n",
    "# First hidden layer with 6 neurons and ReLU activation\n",
    "model2.add(Dense(6, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "\n",
    "# Second hidden layer with 6 neurons and sigmoid activation\n",
    "model2.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "# Output layer with 3 neurons and softmax activation\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile and train the alternative model\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history2 = model2.fit(X_train_scaled, y_train, batch_size=32, epochs=100, \n",
    "                      validation_data=(X_test_scaled, y_test), verbose=0)\n",
    "\n",
    "# Evaluate alternative model\n",
    "test_loss2, test_accuracy2 = model2.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Alternative Model Test Accuracy: {test_accuracy2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
