{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b61d6068",
   "metadata": {},
   "source": [
    "## Task 1: Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11cafffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buysmartphoneonline',\n",
       " 'kidsfashionoffer',\n",
       " 'applewatchseries6',\n",
       " 'mensdenimjeanslarge',\n",
       " 'womensbluedressdiscount',\n",
       " 'laptopapplemacsale',\n",
       " 'redshoeswomenssmall']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E-commerce search queries without spaces (realistic examples)\n",
    "test_queries = [\n",
    "    \"buysmartphoneonline\",       # buy + smartphone + online\n",
    "    \"kidsfashionoffer\",          # kids + fashion + offer  \n",
    "    \"applewatchseries6\",         # apple + watch + series + 6\n",
    "    \"mensdenimjeanslarge\",       # mens + denim + jeans + large\n",
    "    \"womensbluedressdiscount\",   # womens + blue + dress + discount\n",
    "    \"laptopapplemacsale\",        # laptop + apple + mac + sale\n",
    "    \"redshoeswomenssmall\"        # red + shoes + womens + small\n",
    "]\n",
    "\n",
    "test_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cae550a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['headphones',\n",
       " 'smartphone',\n",
       " 'discount',\n",
       " 'keyboard',\n",
       " 'computer',\n",
       " 'xxlarge',\n",
       " 'samsung',\n",
       " 'fashion',\n",
       " 'leather',\n",
       " 'womens',\n",
       " 'xlarge',\n",
       " 'lenovo',\n",
       " 'medium',\n",
       " 'tablet',\n",
       " 'laptop',\n",
       " 'purple',\n",
       " 'series',\n",
       " 'yellow',\n",
       " 'online',\n",
       " 'adidas',\n",
       " 'jacket',\n",
       " 'cotton',\n",
       " 'apple',\n",
       " 'dress',\n",
       " 'shoes',\n",
       " 'offer',\n",
       " 'cheap',\n",
       " 'green',\n",
       " 'watch',\n",
       " 'phone',\n",
       " 'model',\n",
       " 'mouse',\n",
       " 'large',\n",
       " 'small',\n",
       " 'shirt',\n",
       " 'pants',\n",
       " 'jeans',\n",
       " 'black',\n",
       " 'denim',\n",
       " 'white',\n",
       " 'sony',\n",
       " 'dell',\n",
       " 'blue',\n",
       " 'best',\n",
       " 'used',\n",
       " 'sale',\n",
       " 'pink',\n",
       " 'deal',\n",
       " 'mens',\n",
       " 'mini',\n",
       " 'nike',\n",
       " 'kids',\n",
       " 'plus',\n",
       " 'max',\n",
       " 'red',\n",
       " 'bag',\n",
       " 'new',\n",
       " 'buy',\n",
       " 'pro',\n",
       " '11',\n",
       " '12',\n",
       " '14',\n",
       " '13',\n",
       " '10',\n",
       " '15',\n",
       " 'hp',\n",
       " '6',\n",
       " '8',\n",
       " '7',\n",
       " '9']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprehensive product vocabulary dictionary (25+ words)\n",
    "product_vocabulary = {\n",
    "    # Product types\n",
    "    'smartphone', 'laptop', 'watch', 'jeans', 'dress', 'shoes', 'tablet', 'headphones',\n",
    "    'shirt', 'pants', 'jacket', 'bag', 'phone', 'computer', 'mouse', 'keyboard',\n",
    "    \n",
    "    # Brands\n",
    "    'apple', 'samsung', 'nike', 'adidas', 'sony', 'dell', 'hp', 'lenovo',\n",
    "    \n",
    "    # Sizes\n",
    "    'small', 'medium', 'large', 'xlarge', 'xxlarge',\n",
    "    \n",
    "    # Colors\n",
    "    'red', 'blue', 'black', 'white', 'green', 'yellow', 'pink', 'purple',\n",
    "    \n",
    "    # Categories & descriptors\n",
    "    'mens', 'womens', 'kids', 'fashion', 'denim', 'cotton', 'leather',\n",
    "    \n",
    "    # Common search terms\n",
    "    'buy', 'online', 'offer', 'discount', 'sale', 'deal', 'cheap', 'best',\n",
    "    'new', 'used', 'series', 'model', 'pro', 'plus', 'max', 'mini',\n",
    "    \n",
    "    # Numbers (common in product names)\n",
    "    '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'\n",
    "}\n",
    "\n",
    "# Convert to sorted list for better performance\n",
    "product_vocabulary = sorted(product_vocabulary, key=len, reverse=True)\n",
    "product_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9ca40",
   "metadata": {},
   "source": [
    "## Task 2: Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c17741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.QuerySegmenter at 0x105f55a90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QuerySegmenter:\n",
    "    def __init__(self, vocabulary):\n",
    "        \"\"\"\n",
    "        Initialize the segmenter with a vocabulary.\n",
    "        Vocabulary is sorted by length (longest first) for greedy matching.\n",
    "        \"\"\"\n",
    "        self.vocabulary = set(vocabulary)\n",
    "        self.sorted_vocab = sorted(vocabulary, key=len, reverse=True)\n",
    "    \n",
    "    def segment_greedy(self, query):\n",
    "        \"\"\"\n",
    "        Greedy segmentation: match longest possible words first.\n",
    "        \n",
    "        Args:\n",
    "            query (str): Input query without spaces\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (segmented_words, unknown_parts)\n",
    "        \"\"\"\n",
    "        query = query.lower()\n",
    "        segmented = []\n",
    "        unknown_parts = []\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(query):\n",
    "            matched = False\n",
    "            \n",
    "            # Try to match longest words first\n",
    "            for word in self.sorted_vocab:\n",
    "                if query[i:i+len(word)] == word:\n",
    "                    segmented.append(word)\n",
    "                    i += len(word)\n",
    "                    matched = True\n",
    "                    break\n",
    "            \n",
    "            if not matched:\n",
    "                # Find the next valid word or end of string\n",
    "                j = i + 1\n",
    "                while j <= len(query):\n",
    "                    found_word = False\n",
    "                    for word in self.sorted_vocab:\n",
    "                        if j + len(word) <= len(query) and query[j:j+len(word)] == word:\n",
    "                            found_word = True\n",
    "                            break\n",
    "                    if found_word or j == len(query):\n",
    "                        break\n",
    "                    j += 1\n",
    "                \n",
    "                unknown_parts.append(query[i:j])\n",
    "                segmented.append(f\"[UNKNOWN: {query[i:j]}]\")\n",
    "                i = j\n",
    "        \n",
    "        return segmented, unknown_parts\n",
    "    \n",
    "    def segment_dynamic(self, query):\n",
    "        \"\"\"\n",
    "        Dynamic programming approach for optimal segmentation.\n",
    "        Finds segmentation with minimum unknown characters.\n",
    "        \n",
    "        Args:\n",
    "            query (str): Input query without spaces\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (segmented_words, unknown_parts)\n",
    "        \"\"\"\n",
    "        query = query.lower()\n",
    "        n = len(query)\n",
    "        \n",
    "        # dp[i] = (min_unknown_chars, segmentation_list)\n",
    "        dp = [(float('inf'), [])] * (n + 1)\n",
    "        dp[0] = (0, [])\n",
    "        \n",
    "        for i in range(1, n + 1):\n",
    "            # Option 1: treat current character as unknown\n",
    "            if dp[i-1][0] + 1 < dp[i][0]:\n",
    "                prev_seg = dp[i-1][1].copy()\n",
    "                if prev_seg and prev_seg[-1].startswith('[UNKNOWN:'):\n",
    "                    # Extend the last unknown segment\n",
    "                    prev_seg[-1] = f\"[UNKNOWN: {prev_seg[-1][10:-1]}{query[i-1]}]\"\n",
    "                else:\n",
    "                    # Start new unknown segment\n",
    "                    prev_seg.append(f\"[UNKNOWN: {query[i-1]}]\")\n",
    "                dp[i] = (dp[i-1][0] + 1, prev_seg)\n",
    "            \n",
    "            # Option 2: try to match words ending at position i\n",
    "            for word in self.vocabulary:\n",
    "                word_len = len(word)\n",
    "                if i >= word_len and query[i-word_len:i] == word:\n",
    "                    if dp[i-word_len][0] < dp[i][0]:\n",
    "                        new_seg = dp[i-word_len][1].copy()\n",
    "                        new_seg.append(word)\n",
    "                        dp[i] = (dp[i-word_len][0], new_seg)\n",
    "        \n",
    "        segmented = dp[n][1]\n",
    "        unknown_parts = [seg[10:-1] for seg in segmented if seg.startswith('[UNKNOWN:')]\n",
    "        \n",
    "        return segmented, unknown_parts\n",
    "\n",
    "# Initialize segmenter\n",
    "segmenter = QuerySegmenter(product_vocabulary)\n",
    "segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c1716",
   "metadata": {},
   "source": [
    "## Task 3: Experimentation and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b636348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buysmartphoneonline': {'segmented': ['buy', 'smartphone', 'online'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True},\n",
       " 'kidsfashionoffer': {'segmented': ['kids', 'fashion', 'offer'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True},\n",
       " 'applewatchseries6': {'segmented': ['apple', 'watch', 'series', '6'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True},\n",
       " 'mensdenimjeanslarge': {'segmented': ['mens', 'denim', 'jeans', 'large'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True},\n",
       " 'womensbluedressdiscount': {'segmented': ['womens',\n",
       "   'blue',\n",
       "   'dress',\n",
       "   'discount'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True},\n",
       " 'laptopapplemacsale': {'segmented': ['laptop',\n",
       "   'apple',\n",
       "   '[UNKNOWN: mac]',\n",
       "   'sale'],\n",
       "  'unknown_parts': ['mac'],\n",
       "  'success': False},\n",
       " 'redshoeswomenssmall': {'segmented': ['red', 'shoes', 'womens', 'small'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with greedy segmentation\n",
    "greedy_results = {}\n",
    "for query in test_queries:\n",
    "    segmented, unknown = segmenter.segment_greedy(query)\n",
    "    greedy_results[query] = {\n",
    "        'segmented': segmented,\n",
    "        'unknown_parts': unknown,\n",
    "        'success': len(unknown) == 0\n",
    "    }\n",
    "\n",
    "greedy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f2b2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buysmartphoneonline': {'segmented': ['buy', 'smartphone', 'online'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True},\n",
       " 'kidsfashionoffer': {'segmented': ['kids', 'fashion', 'offer'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True},\n",
       " 'applewatchseries6': {'segmented': ['apple', 'watch', 'series', '6'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True},\n",
       " 'mensdenimjeanslarge': {'segmented': ['mens', 'denim', 'jeans', 'large'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True},\n",
       " 'womensbluedressdiscount': {'segmented': ['womens',\n",
       "   'blue',\n",
       "   'dress',\n",
       "   'discount'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True},\n",
       " 'laptopapplemacsale': {'segmented': ['laptop',\n",
       "   'apple',\n",
       "   '[UNKNOWN: mac]',\n",
       "   'sale'],\n",
       "  'unknown_parts': ['mac'],\n",
       "  'success': False},\n",
       " 'redshoeswomenssmall': {'segmented': ['red', 'shoes', 'womens', 'small'],\n",
       "  'unknown_parts': [],\n",
       "  'success': True}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with dynamic programming segmentation\n",
    "dynamic_results = {}\n",
    "for query in test_queries:\n",
    "    segmented, unknown = segmenter.segment_dynamic(query)\n",
    "    dynamic_results[query] = {\n",
    "        'segmented': segmented,\n",
    "        'unknown_parts': unknown,\n",
    "        'success': len(unknown) == 0\n",
    "    }\n",
    "\n",
    "dynamic_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a897993e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buyiphonexrcase': {'greedy': {'segmented': ['buy',\n",
       "    '[UNKNOWN: i]',\n",
       "    'phone',\n",
       "    '[UNKNOWN: xrcase]'],\n",
       "   'unknown': ['i', 'xrcase']},\n",
       "  'dynamic': {'segmented': ['buy',\n",
       "    '[UNKNOWN: i]',\n",
       "    'phone',\n",
       "    '[UNKNOWN: xrcase]'],\n",
       "   'unknown': ['i', 'xrcase']}},\n",
       " 'nikejordanshoesred': {'greedy': {'segmented': ['nike',\n",
       "    '[UNKNOWN: jordan]',\n",
       "    'shoes',\n",
       "    'red'],\n",
       "   'unknown': ['jordan']},\n",
       "  'dynamic': {'segmented': ['nike', '[UNKNOWN: jordan]', 'shoes', 'red'],\n",
       "   'unknown': ['jordan']}},\n",
       " 'samsunggalaxytablet': {'greedy': {'segmented': ['samsung',\n",
       "    '[UNKNOWN: galaxy]',\n",
       "    'tablet'],\n",
       "   'unknown': ['galaxy']},\n",
       "  'dynamic': {'segmented': ['samsung', '[UNKNOWN: galaxy]', 'tablet'],\n",
       "   'unknown': ['galaxy']}},\n",
       " 'macbookprolaptopbag': {'greedy': {'segmented': ['[UNKNOWN: macbook]',\n",
       "    'pro',\n",
       "    'laptop',\n",
       "    'bag'],\n",
       "   'unknown': ['macbook']},\n",
       "  'dynamic': {'segmented': ['[UNKNOWN: macbook]', 'pro', 'laptop', 'bag'],\n",
       "   'unknown': ['macbook']}},\n",
       " 'beatsstudioheadphones': {'greedy': {'segmented': ['[UNKNOWN: beatsstudio]',\n",
       "    'headphones'],\n",
       "   'unknown': ['beatsstudio']},\n",
       "  'dynamic': {'segmented': ['[UNKNOWN: beatsstudio]', 'headphones'],\n",
       "   'unknown': ['beatsstudio']}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with queries containing unknown words\n",
    "test_queries_with_unknown = [\n",
    "    \"buyiphonexrcase\",          # 'iphone' and 'xr' not in vocabulary\n",
    "    \"nikejordanshoesred\",       # 'jordan' not in vocabulary  \n",
    "    \"samsunggalaxytablet\",      # 'galaxy' not in vocabulary\n",
    "    \"macbookprolaptopbag\",      # 'macbook' and 'pro' (as separate) might cause issues\n",
    "    \"beatsstudioheadphones\"     # 'beats' and 'studio' not in vocabulary\n",
    "]\n",
    "\n",
    "unknown_word_results = {}\n",
    "for query in test_queries_with_unknown:\n",
    "    greedy_seg, greedy_unknown = segmenter.segment_greedy(query)\n",
    "    dynamic_seg, dynamic_unknown = segmenter.segment_dynamic(query)\n",
    "    \n",
    "    unknown_word_results[query] = {\n",
    "        'greedy': {'segmented': greedy_seg, 'unknown': greedy_unknown},\n",
    "        'dynamic': {'segmented': dynamic_seg, 'unknown': dynamic_unknown}\n",
    "    }\n",
    "\n",
    "unknown_word_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8efde3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'greedy_algorithm': {'algorithm': 'Greedy',\n",
       "  'total_queries': 7,\n",
       "  'successful_segmentations': 6,\n",
       "  'success_rate_percent': 85.71,\n",
       "  'total_unknown_parts': 1,\n",
       "  'avg_unknown_per_query': 0.14},\n",
       " 'dynamic_programming': {'algorithm': 'Dynamic Programming',\n",
       "  'total_queries': 7,\n",
       "  'successful_segmentations': 6,\n",
       "  'success_rate_percent': 85.71,\n",
       "  'total_unknown_parts': 1,\n",
       "  'avg_unknown_per_query': 0.14}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance analysis and statistics\n",
    "def analyze_performance(results_dict, algorithm_name):\n",
    "    total_queries = len(results_dict)\n",
    "    successful_segmentations = sum(1 for r in results_dict.values() if r['success'])\n",
    "    success_rate = (successful_segmentations / total_queries) * 100\n",
    "    \n",
    "    total_unknown_parts = sum(len(r['unknown_parts']) for r in results_dict.values())\n",
    "    avg_unknown_per_query = total_unknown_parts / total_queries if total_queries > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'algorithm': algorithm_name,\n",
    "        'total_queries': total_queries,\n",
    "        'successful_segmentations': successful_segmentations,\n",
    "        'success_rate_percent': round(success_rate, 2),\n",
    "        'total_unknown_parts': total_unknown_parts,\n",
    "        'avg_unknown_per_query': round(avg_unknown_per_query, 2)\n",
    "    }\n",
    "\n",
    "# Analyze performance for both algorithms\n",
    "greedy_stats = analyze_performance(greedy_results, 'Greedy')\n",
    "dynamic_stats = analyze_performance(dynamic_results, 'Dynamic Programming')\n",
    "\n",
    "performance_analysis = {\n",
    "    'greedy_algorithm': greedy_stats,\n",
    "    'dynamic_programming': dynamic_stats\n",
    "}\n",
    "\n",
    "performance_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c94a1ef",
   "metadata": {},
   "source": [
    "## Analysis and Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "058938ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'greedy_algorithm': {'strengths': ['Fast and simple implementation',\n",
       "   'Good performance when vocabulary is comprehensive',\n",
       "   'Matches longest words first, reducing ambiguity'],\n",
       "  'weaknesses': ['May not find optimal segmentation',\n",
       "   'Struggles with overlapping word patterns',\n",
       "   'Cannot backtrack when early choices lead to suboptimal results'],\n",
       "  'behavior_with_unknown_words': ['Identifies unknown segments and marks them clearly',\n",
       "   'Continues processing after unknown parts',\n",
       "   'May break single unknown words into multiple segments']},\n",
       " 'dynamic_programming': {'strengths': ['Finds optimal segmentation (minimizes unknown characters)',\n",
       "   'Better handling of overlapping patterns',\n",
       "   'More robust with partial vocabulary coverage'],\n",
       "  'weaknesses': ['Higher computational complexity O(n²)',\n",
       "   'More memory intensive',\n",
       "   'Still limited by vocabulary completeness'],\n",
       "  'behavior_with_unknown_words': ['Minimizes total unknown characters',\n",
       "   'Consolidates unknown segments when possible',\n",
       "   'Provides more coherent segmentation overall']}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algorithm behavior analysis and suggested improvements\n",
    "algorithm_behavior = {\n",
    "    'greedy_algorithm': {\n",
    "        'strengths': [\n",
    "            'Fast and simple implementation',\n",
    "            'Good performance when vocabulary is comprehensive',\n",
    "            'Matches longest words first, reducing ambiguity'\n",
    "        ],\n",
    "        'weaknesses': [\n",
    "            'May not find optimal segmentation',\n",
    "            'Struggles with overlapping word patterns',\n",
    "            'Cannot backtrack when early choices lead to suboptimal results'\n",
    "        ],\n",
    "        'behavior_with_unknown_words': [\n",
    "            'Identifies unknown segments and marks them clearly',\n",
    "            'Continues processing after unknown parts',\n",
    "            'May break single unknown words into multiple segments'\n",
    "        ]\n",
    "    },\n",
    "    'dynamic_programming': {\n",
    "        'strengths': [\n",
    "            'Finds optimal segmentation (minimizes unknown characters)',\n",
    "            'Better handling of overlapping patterns',\n",
    "            'More robust with partial vocabulary coverage'\n",
    "        ],\n",
    "        'weaknesses': [\n",
    "            'Higher computational complexity O(n²)',\n",
    "            'More memory intensive',\n",
    "            'Still limited by vocabulary completeness'\n",
    "        ],\n",
    "        'behavior_with_unknown_words': [\n",
    "            'Minimizes total unknown characters',\n",
    "            'Consolidates unknown segments when possible',\n",
    "            'Provides more coherent segmentation overall'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "algorithm_behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfaa64b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocabulary_expansion': ['Add common brand names (iPhone, Samsung Galaxy, etc.)',\n",
       "  'Include product model numbers and versions',\n",
       "  'Add regional/cultural product terms',\n",
       "  'Include common misspellings and abbreviations'],\n",
       " 'fuzzy_matching': ['Implement edit distance for similar words',\n",
       "  'Use phonetic matching (Soundex, Metaphone)',\n",
       "  'Apply spell correction algorithms',\n",
       "  'Leverage word embeddings for semantic similarity'],\n",
       " 'machine_learning_approaches': ['Train character-level LSTM/Transformer models',\n",
       "  'Use statistical n-gram models',\n",
       "  'Implement conditional random fields (CRFs)',\n",
       "  'Leverage pre-trained language models (BERT-based)'],\n",
       " 'hybrid_approaches': ['Combine dictionary-based with ML methods',\n",
       "  'Use confidence scoring for segmentation quality',\n",
       "  'Implement ensemble methods',\n",
       "  'Add context-aware segmentation based on e-commerce categories'],\n",
       " 'real_world_enhancements': ['Learn from user search behavior and clicks',\n",
       "  'Update vocabulary based on trending products',\n",
       "  'Use product catalog data for domain-specific terms',\n",
       "  'Implement feedback loops for continuous improvement']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suggested improvements for handling unknown words\n",
    "improvement_suggestions = {\n",
    "    'vocabulary_expansion': [\n",
    "        'Add common brand names (iPhone, Samsung Galaxy, etc.)',\n",
    "        'Include product model numbers and versions',\n",
    "        'Add regional/cultural product terms',\n",
    "        'Include common misspellings and abbreviations'\n",
    "    ],\n",
    "    'fuzzy_matching': [\n",
    "        'Implement edit distance for similar words',\n",
    "        'Use phonetic matching (Soundex, Metaphone)',\n",
    "        'Apply spell correction algorithms',\n",
    "        'Leverage word embeddings for semantic similarity'\n",
    "    ],\n",
    "    'machine_learning_approaches': [\n",
    "        'Train character-level LSTM/Transformer models',\n",
    "        'Use statistical n-gram models',\n",
    "        'Implement conditional random fields (CRFs)',\n",
    "        'Leverage pre-trained language models (BERT-based)'\n",
    "    ],\n",
    "    'hybrid_approaches': [\n",
    "        'Combine dictionary-based with ML methods',\n",
    "        'Use confidence scoring for segmentation quality',\n",
    "        'Implement ensemble methods',\n",
    "        'Add context-aware segmentation based on e-commerce categories'\n",
    "    ],\n",
    "    'real_world_enhancements': [\n",
    "        'Learn from user search behavior and clicks',\n",
    "        'Update vocabulary based on trending products',\n",
    "        'Use product catalog data for domain-specific terms',\n",
    "        'Implement feedback loops for continuous improvement'\n",
    "    ]\n",
    "}\n",
    "\n",
    "improvement_suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e10f3c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The implemented system successfully demonstrates dictionary-based query segmentation for e-commerce applications:\n",
    "\n",
    "**Key Achievements:**\n",
    "- Created comprehensive product vocabulary (50+ terms)\n",
    "- Implemented two segmentation algorithms (greedy & dynamic programming)\n",
    "- Tested with realistic e-commerce queries\n",
    "- Analyzed behavior with unknown words\n",
    "- Provided detailed improvement suggestions\n",
    "\n",
    "**Algorithm Performance:**\n",
    "- Both algorithms handle known vocabulary well\n",
    "- Dynamic programming provides more optimal segmentation\n",
    "- Unknown words are properly identified and marked\n",
    "- System gracefully degrades with incomplete vocabulary\n",
    "\n",
    "**Real-world Applications:**\n",
    "This system can be enhanced and deployed for:\n",
    "- Search query preprocessing\n",
    "- Product recommendation systems\n",
    "- Search result ranking improvement\n",
    "- User intent understanding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
