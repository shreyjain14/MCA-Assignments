{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb853ad",
   "metadata": {},
   "source": [
    "## A. Dataset Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af9cf845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2d45ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "urllib.request.urlretrieve(url, 'shakespeare.txt')\n",
    "with open('shakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()\n",
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72d5dc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1053696"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = raw_text.lower()\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "text = re.sub(r'\\d+', '', text)\n",
    "text = re.sub(r'\\s+', ' ', text).strip()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b747e",
   "metadata": {},
   "source": [
    "## Tokenization & Sequence Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be7aef15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vocabulary size: 12847'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split()\n",
    "unique_words = sorted(set(words))\n",
    "vocab_size = len(unique_words)\n",
    "\n",
    "word_to_index = {word: idx for idx, word in enumerate(unique_words)}\n",
    "index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
    "\n",
    "encoded_text = [word_to_index[word] for word in words]\n",
    "\n",
    "f'Vocabulary size: {vocab_size}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d16db7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202609, 10), (202609,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 10\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(encoded_text) - sequence_length):\n",
    "    X.append(encoded_text[i:i + sequence_length])\n",
    "    y.append(encoded_text[i + sequence_length])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0ea19d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training set: (162087, 10), Validation set: (40522, 10)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ratio = 0.8\n",
    "split_idx = int(len(X) * split_ratio)\n",
    "\n",
    "X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "\n",
    "f'Training set: {X_train.shape}, Validation set: {X_val.shape}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d13dab",
   "metadata": {},
   "source": [
    "## B. LSTM-based Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6e8df8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,644,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12847</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,657,263</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,644,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12847\u001b[0m)          │     \u001b[38;5;34m1,657,263\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,728,815</span> (14.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,728,815\u001b[0m (14.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,728,815</span> (14.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,728,815\u001b[0m (14.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_model = Sequential([\n",
    "    Embedding(vocab_size, 128, input_length=sequence_length),\n",
    "    LSTM(256, return_sequences=False),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "lstm_model.build((None, sequence_length))\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38795bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_start_time = time.time()\n",
    "lstm_history = lstm_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=25, batch_size=64, verbose=0)\n",
    "lstm_training_time = time.time() - lstm_start_time\n",
    "\n",
    "f'LSTM Training Time: {lstm_training_time:.2f} seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fb499",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(lstm_history.history['loss'], label='Training Loss')\n",
    "plt.plot(lstm_history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('LSTM Model - Loss Curves')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(lstm_history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(lstm_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('LSTM Model - Accuracy Curves')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bfa659",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_val_predictions = lstm_model.predict(X_val, verbose=0)\n",
    "lstm_val_loss = np.mean(-np.log(np.max(lstm_val_predictions, axis=1) + 1e-10))\n",
    "lstm_perplexity = np.exp(lstm_val_loss)\n",
    "\n",
    "f'LSTM Validation Loss: {lstm_val_loss:.4f}'\n",
    "f'LSTM Perplexity: {lstm_perplexity:.4f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_lstm(start_phrase, num_words=8, temperature=0.7):\n",
    "    words = start_phrase.lower().split()\n",
    "    \n",
    "    for _ in range(num_words):\n",
    "        input_words = words[-sequence_length:]\n",
    "        \n",
    "        while len(input_words) < sequence_length:\n",
    "            input_words = [input_words[0]] + input_words\n",
    "        \n",
    "        encoded_input = np.array([[word_to_index.get(word, 0) for word in input_words]])\n",
    "        \n",
    "        predictions = lstm_model.predict(encoded_input, verbose=0)[0]\n",
    "        predictions = np.power(predictions, 1/temperature)\n",
    "        predictions = predictions / np.sum(predictions)\n",
    "        \n",
    "        next_word_idx = np.random.choice(len(predictions), p=predictions)\n",
    "        next_word = index_to_word.get(next_word_idx, 'unknown')\n",
    "        words.append(next_word)\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321f3d5",
   "metadata": {},
   "source": [
    "## C. GRU-based Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79399112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,644,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">296,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12847</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,657,263</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,644,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m296,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12847\u001b[0m)          │     \u001b[38;5;34m1,657,263\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,631,023</span> (13.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,631,023\u001b[0m (13.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,631,023</span> (13.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,631,023\u001b[0m (13.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gru_model = Sequential([\n",
    "    Embedding(vocab_size, 128, input_length=sequence_length),\n",
    "    GRU(256, return_sequences=False),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "gru_model.build((None, sequence_length))\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ae353",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_start_time = time.time()\n",
    "gru_history = gru_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=25, batch_size=64, verbose=0)\n",
    "gru_training_time = time.time() - gru_start_time\n",
    "\n",
    "f'GRU Training Time: {gru_training_time:.2f} seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(gru_history.history['loss'], label='Training Loss')\n",
    "plt.plot(gru_history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('GRU Model - Loss Curves')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(gru_history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(gru_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('GRU Model - Accuracy Curves')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_val_predictions = gru_model.predict(X_val, verbose=0)\n",
    "gru_val_loss = np.mean(-np.log(np.max(gru_val_predictions, axis=1) + 1e-10))\n",
    "gru_perplexity = np.exp(gru_val_loss)\n",
    "\n",
    "f'GRU Validation Loss: {gru_val_loss:.4f}'\n",
    "f'GRU Perplexity: {gru_perplexity:.4f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41654b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_gru(start_phrase, num_words=8, temperature=0.7):\n",
    "    words = start_phrase.lower().split()\n",
    "    \n",
    "    for _ in range(num_words):\n",
    "        input_words = words[-sequence_length:]\n",
    "        \n",
    "        while len(input_words) < sequence_length:\n",
    "            input_words = [input_words[0]] + input_words\n",
    "        \n",
    "        encoded_input = np.array([[word_to_index.get(word, 0) for word in input_words]])\n",
    "        \n",
    "        predictions = gru_model.predict(encoded_input, verbose=0)[0]\n",
    "        predictions = np.power(predictions, 1/temperature)\n",
    "        predictions = predictions / np.sum(predictions)\n",
    "        \n",
    "        next_word_idx = np.random.choice(len(predictions), p=predictions)\n",
    "        next_word = index_to_word.get(next_word_idx, 'unknown')\n",
    "        words.append(next_word)\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b84d1e3",
   "metadata": {},
   "source": [
    "## D. Comparison & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e810e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_params = lstm_model.count_params()\n",
    "gru_params = gru_model.count_params()\n",
    "\n",
    "lstm_final_val_loss = lstm_history.history['val_loss'][-1]\n",
    "gru_final_val_loss = gru_history.history['val_loss'][-1]\n",
    "\n",
    "lstm_final_accuracy = lstm_history.history['val_accuracy'][-1]\n",
    "gru_final_accuracy = gru_history.history['val_accuracy'][-1]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Training Time (seconds)', 'Model Parameters', 'Final Validation Loss', 'Final Validation Accuracy', 'Perplexity'],\n",
    "    'LSTM': [f'{lstm_training_time:.2f}', lstm_params, f'{lstm_final_val_loss:.4f}', f'{lstm_final_accuracy:.4f}', f'{lstm_perplexity:.4f}'],\n",
    "    'GRU': [f'{gru_training_time:.2f}', gru_params, f'{gru_final_val_loss:.4f}', f'{gru_final_accuracy:.4f}', f'{gru_perplexity:.4f}']\n",
    "})\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].plot(lstm_history.history['val_loss'], label='LSTM', linewidth=2)\n",
    "axes[0, 0].plot(gru_history.history['val_loss'], label='GRU', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Validation Loss')\n",
    "axes[0, 0].set_title('Validation Loss Comparison')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid()\n",
    "\n",
    "axes[0, 1].plot(lstm_history.history['val_accuracy'], label='LSTM', linewidth=2)\n",
    "axes[0, 1].plot(gru_history.history['val_accuracy'], label='GRU', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Validation Accuracy')\n",
    "axes[0, 1].set_title('Validation Accuracy Comparison')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid()\n",
    "\n",
    "models = ['LSTM', 'GRU']\n",
    "training_times = [lstm_training_time, gru_training_time]\n",
    "axes[1, 0].bar(models, training_times, color=['blue', 'orange'])\n",
    "axes[1, 0].set_ylabel('Time (seconds)')\n",
    "axes[1, 0].set_title('Training Time Comparison')\n",
    "axes[1, 0].grid(axis='y')\n",
    "\n",
    "perplexities = [lstm_perplexity, gru_perplexity]\n",
    "axes[1, 1].bar(models, perplexities, color=['blue', 'orange'])\n",
    "axes[1, 1].set_ylabel('Perplexity')\n",
    "axes[1, 1].set_title('Perplexity Comparison')\n",
    "axes[1, 1].grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff143a6c",
   "metadata": {},
   "source": [
    "## Text Generation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = ['the king', 'love is', 'we must']\n",
    "\n",
    "lstm_samples = []\n",
    "gru_samples = []\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    lstm_text = generate_text_lstm(prompt, num_words=10, temperature=0.8)\n",
    "    gru_text = generate_text_gru(prompt, num_words=10, temperature=0.8)\n",
    "    lstm_samples.append(lstm_text)\n",
    "    gru_samples.append(gru_text)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Prompt': test_prompts,\n",
    "    'LSTM Generated': lstm_samples,\n",
    "    'GRU Generated': gru_samples\n",
    "})\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86deb6c8",
   "metadata": {},
   "source": [
    "## Analysis & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = f\"\"\"\n",
    "LSTM vs GRU ANALYSIS:\n",
    "\n",
    "1. TRAINING TIME:\n",
    "   LSTM: {lstm_training_time:.2f}s\n",
    "   GRU: {gru_training_time:.2f}s\n",
    "   Faster Model: {'GRU' if gru_training_time < lstm_training_time else 'LSTM'}\n",
    "\n",
    "2. MODEL COMPLEXITY:\n",
    "   LSTM Parameters: {lstm_params:,}\n",
    "   GRU Parameters: {gru_params:,}\n",
    "   Simpler Model: {'GRU' if gru_params < lstm_params else 'LSTM'} ({abs(lstm_params - gru_params):,} fewer params)\n",
    "\n",
    "3. VALIDATION LOSS:\n",
    "   LSTM: {lstm_final_val_loss:.4f}\n",
    "   GRU: {gru_final_val_loss:.4f}\n",
    "   Better: {'GRU' if gru_final_val_loss < lstm_final_val_loss else 'LSTM'}\n",
    "\n",
    "4. VALIDATION ACCURACY:\n",
    "   LSTM: {lstm_final_accuracy:.4f}\n",
    "   GRU: {gru_final_accuracy:.4f}\n",
    "   Better: {'GRU' if gru_final_accuracy > lstm_final_accuracy else 'LSTM'}\n",
    "\n",
    "5. PERPLEXITY:\n",
    "   LSTM: {lstm_perplexity:.4f}\n",
    "   GRU: {gru_perplexity:.4f}\n",
    "   Better: {'GRU' if gru_perplexity < lstm_perplexity else 'LSTM'} (lower is better)\n",
    "\n",
    "CONCLUSION:\n",
    "{'GRU outperforms LSTM' if gru_final_val_loss < lstm_final_val_loss else 'LSTM outperforms GRU'} on the Tiny Shakespeare dataset.\n",
    "The GRU model is more computationally efficient with fewer parameters while maintaining comparable performance.\n",
    "Both models successfully learn next-word prediction patterns from Shakespeare text.\n",
    "\"\"\"\n",
    "\n",
    "analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
