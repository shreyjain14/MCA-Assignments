{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8939664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(path):\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    raw_dir = os.path.join(path, 'raw')\n",
    "    processed_dir = os.path.join(path, 'processed')\n",
    "    \n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    for file in os.listdir(raw_dir):\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(raw_dir, file), 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "                tokens = text.split()\n",
    "                with open(os.path.join(processed_dir, file[:-4] + '.json'), 'w', encoding='utf-8') as out_f:\n",
    "                    json.dump(tokens, out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acabafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a3c12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_n_grams(path, n=3):\n",
    "    import os\n",
    "    import csv\n",
    "    from collections import defaultdict\n",
    "\n",
    "    tokenized_dir = os.path.join(path, 'processed')\n",
    "    n_grams_dir = os.path.join(path, 'n_grams')\n",
    "    \n",
    "    os.makedirs(n_grams_dir, exist_ok=True)\n",
    "    \n",
    "    n_grams = defaultdict(int)\n",
    "\n",
    "    for file in os.listdir(tokenized_dir):\n",
    "        if file.endswith('.json'):\n",
    "            import json\n",
    "            with open(os.path.join(tokenized_dir, file), 'r', encoding='utf-8') as f:\n",
    "                tokens = json.load(f)\n",
    "                for i in range(len(tokens) - n + 1):\n",
    "                    n_gram = tuple(tokens[i:i+n])\n",
    "                    n_grams[n_gram] += 1\n",
    "\n",
    "    # Create column headers: word_1, word_2, ..., word_n, count\n",
    "    headers = [f'word_{i+1}' for i in range(n)] + ['count']\n",
    "    \n",
    "    with open(os.path.join(n_grams_dir, f'n_grams_{n}.csv'), 'w', newline='', encoding='utf-8') as out_f:\n",
    "        writer = csv.writer(out_f)\n",
    "        writer.writerow(headers)\n",
    "        for n_gram, count in n_grams.items():\n",
    "            row = list(n_gram) + [count]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a176da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_n_grams('data', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42b0f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "def generate_story(starting_words, length=100, n_grams_file='data/n_grams/n_grams_3.csv'):\n",
    "    df = pd.read_csv(n_grams_file)\n",
    "    \n",
    "    words = starting_words.split()\n",
    "    if len(words) != 2:\n",
    "        return \"Error: Please provide exactly 2 starting words\"\n",
    "    \n",
    "    story = words.copy()\n",
    "    \n",
    "    while len(story) < length:\n",
    "        first_word = story[-2]\n",
    "        second_word = story[-1]\n",
    "        \n",
    "        matching = df[(df['word_1'] == first_word) & (df['word_2'] == second_word)].copy()\n",
    "        \n",
    "        if len(matching) > 0:\n",
    "            total_count = matching['count'].sum()\n",
    "            matching['probability'] = matching['count'] / total_count\n",
    "            \n",
    "            next_word = random.choices(matching['word_3'].values, weights=matching['probability'].values)[0]\n",
    "            story.append(next_word)\n",
    "        else:\n",
    "            random_word = df.sample(1)['word_3'].values[0]\n",
    "            story.append(random_word)\n",
    "    \n",
    "    return ' '.join(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12c3a713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Harry Potter And The Prisoner of Azkaban CHAPTER NINETEEN The Servant of Lord Voldemort.’ Harry stared. Snape-the-teenager had a very strange to be back in my time,” said Ron, picking up the blankets drawn right over his ears. 'You've got to read Voldemort’s thoughts, because for a moment, then he remembered how Snape had tried to get to work. I will be escorted to each other for a while, before he started emptying his drawers. Then, while Harry and Ron’s utter astonishment, was Tonks, walking toward them, and Harry kept his mind affected?” “Saintlike,” repeated George, opening his own, then\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story = generate_story(\"Harry Potter\", length=100)\n",
    "\n",
    "story"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
