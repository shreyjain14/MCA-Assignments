{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676ea7ab",
   "metadata": {},
   "source": [
    "1. Take an input matrix with size 5x5 and a kernel with size 3x3, perform convolution with\n",
    "stride being 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b435ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution (stride=1):\n",
      " [[2. 1. 2.]\n",
      " [1. 2. 3.]\n",
      " [4. 2. 1.]]\n",
      "Convolution (stride=2):\n",
      " [[2. 2.]\n",
      " [4. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define input matrix and kernel\n",
    "input_matrix = np.array([[1, 0, 1, 1, 0],\n",
    "                         [0, 0, 0, 1, 1],\n",
    "                         [1, 0, 0, 0, 1],\n",
    "                         [0, 1, 1, 1, 0],\n",
    "                         [1, 1, 0, 1, 0]])\n",
    "\n",
    "kernel = np.array([[1, 0, 0],\n",
    "                   [0, 0, 1],\n",
    "                   [1, 1, 0]])\n",
    "\n",
    "def conv(X, K, stride=1):\n",
    "    X_h, X_w = X.shape\n",
    "    K_h, K_w = K.shape\n",
    "    out_h = (X_h - K_h) // stride + 1\n",
    "    out_w = (X_w - K_w) // stride + 1\n",
    "    out = np.zeros((out_h, out_w))\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            region = X[i*stride:i*stride+K_h, j*stride:j*stride+K_w]\n",
    "            out[i, j] = np.sum(region * K)\n",
    "    return out\n",
    "\n",
    "conv_stride_1 = conv(input_matrix, kernel, stride=1)\n",
    "conv_stride_2 = conv(input_matrix, kernel, stride=2)\n",
    "\n",
    "print('Convolution (stride=1):\\n', conv_stride_1)\n",
    "print('Convolution (stride=2):\\n', conv_stride_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde7471",
   "metadata": {},
   "source": [
    "2. Apply max-pooling, average-pooling and sum-pooling to the results from above\n",
    "convolutions [Q1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18478ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Pool (stride=1):\n",
      " [[2. 3.]\n",
      " [4. 1.]]\n",
      "Avg Pool (stride=1):\n",
      " [[1.5  1.25]\n",
      " [1.5  0.25]]\n",
      "Sum Pool (stride=1):\n",
      " [[6. 5.]\n",
      " [6. 1.]]\n",
      "Max Pool (stride=2):\n",
      " [[4.]]\n",
      "Avg Pool (stride=2):\n",
      " [[2.25]]\n",
      "Sum Pool (stride=2):\n",
      " [[9.]]\n"
     ]
    }
   ],
   "source": [
    "def pool(X, pool_size=2, mode='max', stride=1):\n",
    "    h, w = X.shape\n",
    "    out_h = (h - pool_size) // stride + 1\n",
    "    out_w = (w - pool_size) // stride + 1\n",
    "    out = np.zeros((out_h, out_w))\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            region = X[i*stride:i*stride+pool_size, j*stride:j*stride+pool_size]\n",
    "            if mode == 'max':\n",
    "                out[i, j] = np.max(region)\n",
    "            elif mode == 'avg':\n",
    "                out[i, j] = np.mean(region)\n",
    "            elif mode == 'sum':\n",
    "                out[i, j] = np.sum(region)\n",
    "    return out\n",
    "\n",
    "# added a zero padding to conv_stride_1 to make it 4x4 for non-overlapping pooling\n",
    "conv_stride_1_padded = np.pad(conv_stride_1, ((0,1),(0,1)), mode='constant')\n",
    "\n",
    "max_pool_1 = pool(conv_stride_1_padded, pool_size=2, mode='max', stride=2)\n",
    "avg_pool_1 = pool(conv_stride_1_padded, pool_size=2, mode='avg', stride=2)\n",
    "sum_pool_1 = pool(conv_stride_1_padded, pool_size=2, mode='sum', stride=2)\n",
    "\n",
    "# pooling for stride=2 convolution\n",
    "max_pool_2 = pool(conv_stride_2, pool_size=2, mode='max')\n",
    "avg_pool_2 = pool(conv_stride_2, pool_size=2, mode='avg')\n",
    "sum_pool_2 = pool(conv_stride_2, pool_size=2, mode='sum')\n",
    "\n",
    "print('Max Pool (stride=1):\\n', max_pool_1)\n",
    "print('Avg Pool (stride=1):\\n', avg_pool_1)\n",
    "print('Sum Pool (stride=1):\\n', sum_pool_1)\n",
    "\n",
    "print('Max Pool (stride=2):\\n', max_pool_2)\n",
    "print('Avg Pool (stride=2):\\n', avg_pool_2)\n",
    "print('Sum Pool (stride=2):\\n', sum_pool_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae78bab",
   "metadata": {},
   "source": [
    "3. Visualize the flattened version of the pooled feature maps from [Q2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae76505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened Max Pool (stride=1): [2. 3. 4. 1.]\n",
      "Flattened Avg Pool (stride=1): [1.5  1.25 1.5  0.25]\n",
      "Flattened Sum Pool (stride=1): [6. 5. 6. 1.]\n",
      "Flattened Max Pool (stride=2): [4.]\n",
      "Flattened Avg Pool (stride=2): [2.25]\n",
      "Flattened Sum Pool (stride=2): [9.]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten pooled feature maps\n",
    "flat_max_pool_1 = max_pool_1.flatten()\n",
    "flat_avg_pool_1 = avg_pool_1.flatten()\n",
    "flat_sum_pool_1 = sum_pool_1.flatten()\n",
    "\n",
    "flat_max_pool_2 = max_pool_2.flatten()\n",
    "flat_avg_pool_2 = avg_pool_2.flatten()\n",
    "flat_sum_pool_2 = sum_pool_2.flatten()\n",
    "\n",
    "print('Flattened Max Pool (stride=1):', flat_max_pool_1)\n",
    "print('Flattened Avg Pool (stride=1):', flat_avg_pool_1)\n",
    "print('Flattened Sum Pool (stride=1):', flat_sum_pool_1)\n",
    "\n",
    "print('Flattened Max Pool (stride=2):', flat_max_pool_2)\n",
    "print('Flattened Avg Pool (stride=2):', flat_avg_pool_2)\n",
    "print('Flattened Sum Pool (stride=2):', flat_sum_pool_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da825713",
   "metadata": {},
   "source": [
    "4. With weights being randomly chosen and bias being 1, learn the weights and bias over an\n",
    "epoch for the flattened arrays from [Q3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded2bb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=22.01879993172998, Weights=[ 0.44978996 -0.20865059  0.55384015  1.49956776], Bias=[0.9765379 0.9765379 0.9765379 0.9765379]\n",
      "Epoch 2: Loss=15.721973621253504, Weights=[ 0.41013901 -0.26812701  0.47453826  1.47974229], Bias=[0.95671243 0.95671243 0.95671243 0.95671243]\n",
      "Epoch 3: Loss=11.225882214915531, Weights=[ 0.37663397 -0.31838458  0.40752817  1.46298976], Bias=[0.93995991 0.93995991 0.93995991 0.93995991]\n",
      "Epoch 4: Loss=8.015560548505062, Weights=[ 0.3483222  -0.36085223  0.35090464  1.44883388], Bias=[0.92580402 0.92580402 0.92580402 0.92580402]\n",
      "Epoch 5: Loss=5.723310620646326, Weights=[ 0.32439876 -0.39673739  0.30305775  1.43687216], Bias=[0.9138423 0.9138423 0.9138423 0.9138423]\n",
      "Epoch 6: Loss=4.0865868659069955, Weights=[ 0.30418345 -0.42706035  0.26262714  1.42676451], Bias=[0.90373465 0.90373465 0.90373465 0.90373465]\n",
      "Epoch 7: Loss=2.917925186929242, Weights=[ 0.28710152 -0.45268326  0.22846327  1.41822354], Bias=[0.89519368 0.89519368 0.89519368 0.89519368]\n",
      "Epoch 8: Loss=2.083471531597151, Weights=[ 0.27266728 -0.47433461  0.19959479  1.41100642], Bias=[0.88797656 0.88797656 0.88797656 0.88797656]\n",
      "Epoch 9: Loss=1.4876507603486566, Weights=[ 0.26047035 -0.49263     0.17520094  1.40490796], Bias=[0.8818781 0.8818781 0.8818781 0.8818781]\n",
      "Epoch 10: Loss=1.0622198341579494, Weights=[ 0.25016395 -0.50808961  0.15458813  1.39975475], Bias=[0.8767249 0.8767249 0.8767249 0.8767249]\n",
      "Epoch 11: Loss=0.7584515170846297, Weights=[ 0.24145503 -0.52115298  0.1371703   1.3954003 ], Bias=[0.87237044 0.87237044 0.87237044 0.87237044]\n",
      "Epoch 12: Loss=0.5415533444863534, Weights=[ 0.234096   -0.53219152  0.12245224  1.39172078], Bias=[0.86869093 0.86869093 0.86869093 0.86869093]\n",
      "Epoch 13: Loss=0.38668262679686816, Weights=[ 0.22787762 -0.5415191   0.11001548  1.38861159], Bias=[0.86558174 0.86558174 0.86558174 0.86558174]\n",
      "Epoch 14: Loss=0.27610106259863404, Weights=[ 0.22262309 -0.54940089  0.09950641  1.38598433], Bias=[0.86295447 0.86295447 0.86295447 0.86295447]\n",
      "Epoch 15: Loss=0.1971430612219896, Weights=[ 0.21818301 -0.55606101  0.09062626  1.38376429], Bias=[0.86073443 0.86073443 0.86073443 0.86073443]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "x = flat_max_pool_1\n",
    "w = np.random.randn(len(x))\n",
    "b = 1.0\n",
    "target = np.ones_like(x)  # dummy target \n",
    "lr = 0.01\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = np.dot(x, w) + b\n",
    "    loss = np.mean((y_pred - target)**2)\n",
    "    \n",
    "    # Backward pass - gradient descent\n",
    "    grad_w = 2 * (y_pred - target) * x / len(x)\n",
    "    grad_b = 2 * (y_pred - target) / len(x)\n",
    "    \n",
    "    w -= lr * grad_w\n",
    "    b -= lr * grad_b\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Loss={loss}, Weights={w}, Bias={b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a721fe40",
   "metadata": {},
   "source": [
    "5. Design and implement a Convolutional Neural Network (CNN) to classify images from\n",
    "MNIST, CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e03465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f3aee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joela\\Software_Projects\\Neural Networks\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9469 - loss: 0.1816 - val_accuracy: 0.9815 - val_loss: 0.0647\n",
      "Epoch 2/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9469 - loss: 0.1816 - val_accuracy: 0.9815 - val_loss: 0.0647\n",
      "Epoch 2/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9815 - loss: 0.0629 - val_accuracy: 0.9798 - val_loss: 0.0669\n",
      "Epoch 3/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9815 - loss: 0.0629 - val_accuracy: 0.9798 - val_loss: 0.0669\n",
      "Epoch 3/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0424 - val_accuracy: 0.9872 - val_loss: 0.0490\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0424 - val_accuracy: 0.9872 - val_loss: 0.0490\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0532\n",
      "MNIST Test accuracy: 0.9833999872207642\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0532\n",
      "MNIST Test accuracy: 0.9833999872207642\n"
     ]
    }
   ],
   "source": [
    "# MNIST Model\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train[..., np.newaxis] / 255.0\n",
    "x_test = x_test[..., np.newaxis] / 255.0\n",
    "\n",
    "model_mnist = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_mnist.compile(optimizer='adam',\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "model_mnist.fit(x_train, y_train, epochs=3, validation_split=0.1)\n",
    "test_loss, test_acc = model_mnist.evaluate(x_test, y_test)\n",
    "print('MNIST Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847072ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 24ms/step - accuracy: 0.4802 - loss: 1.4393 - val_accuracy: 0.6122 - val_loss: 1.0872\n",
      "Epoch 2/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 24ms/step - accuracy: 0.4802 - loss: 1.4393 - val_accuracy: 0.6122 - val_loss: 1.0872\n",
      "Epoch 2/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - accuracy: 0.6469 - loss: 1.0013 - val_accuracy: 0.6934 - val_loss: 0.8863\n",
      "Epoch 3/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 22ms/step - accuracy: 0.6469 - loss: 1.0013 - val_accuracy: 0.6934 - val_loss: 0.8863\n",
      "Epoch 3/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 22ms/step - accuracy: 0.7076 - loss: 0.8357 - val_accuracy: 0.7140 - val_loss: 0.8191\n",
      "Epoch 4/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 22ms/step - accuracy: 0.7076 - loss: 0.8357 - val_accuracy: 0.7140 - val_loss: 0.8191\n",
      "Epoch 4/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.7476 - loss: 0.7277 - val_accuracy: 0.7204 - val_loss: 0.8056\n",
      "Epoch 5/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.7476 - loss: 0.7277 - val_accuracy: 0.7204 - val_loss: 0.8056\n",
      "Epoch 5/5\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.7772 - loss: 0.6348 - val_accuracy: 0.7200 - val_loss: 0.8408\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.7772 - loss: 0.6348 - val_accuracy: 0.7200 - val_loss: 0.8408\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7072 - loss: 0.8638\n",
      "CIFAR-10 Test accuracy: 0.7071999907493591\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7072 - loss: 0.8638\n",
      "CIFAR-10 Test accuracy: 0.7071999907493591\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 Model\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train_c, y_train_c), (x_test_c, y_test_c) = cifar10.load_data()\n",
    "x_train_c = x_train_c / 255.0\n",
    "x_test_c = x_test_c / 255.0\n",
    "\n",
    "model_cifar = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_cifar.compile(optimizer='adam',\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "model_cifar.fit(x_train_c, y_train_c, epochs=5, validation_split=0.1)\n",
    "test_loss_c, test_acc_c = model_cifar.evaluate(x_test_c, y_test_c)\n",
    "print('CIFAR-10 Test accuracy:', test_acc_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f914b5d",
   "metadata": {},
   "source": [
    "# testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8011d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Predicted digit: 5\n",
      "Predicted digit: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Predicted class: horse\n",
      "Predicted class: horse\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# MNIST Image Classification Test\n",
    "def test_mnist_image(model):\n",
    "    img_path = input('Enter path to a grayscale digit image: ')\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, (28, 28))\n",
    "    plt.imshow(img_resized, cmap='gray')\n",
    "    plt.title('Input Image for MNIST')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    img_array = img_resized.astype('float32') / 255.0\n",
    "    img_array = img_array.reshape(1, 28, 28, 1)\n",
    "    pred = model.predict(img_array)\n",
    "    print('Predicted digit:', pred.argmax())\n",
    "\n",
    "# CIFAR-10 Image Classification Test\n",
    "def test_cifar10_image(model):\n",
    "    img_path = input('Enter path to a color image: ')\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (32, 32))\n",
    "    plt.imshow(img_resized)\n",
    "    plt.title('Input Image for CIFAR-10')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    img_array = img_resized.astype('float32') / 255.0\n",
    "    img_array = img_array.reshape(1, 32, 32, 3)\n",
    "    pred = model.predict(img_array)\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    print('Predicted class:', class_names[pred.argmax()])\n",
    "\n",
    "test_mnist_image(model_mnist)\n",
    "test_cifar10_image(model_cifar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
