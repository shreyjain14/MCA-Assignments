{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc0cfbba",
   "metadata": {},
   "source": [
    "1. Load text → build char-to-index and index-to-char mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f9192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 439478 Vocab size: 82\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = r\"./../../../nlp/autocomplete/data/raw/01 Harry Potter and the Sorcerers Stone.txt\"\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
    "idx_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "vocab_size = len(chars)\n",
    "print(\"Text length:\", len(text), \"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a367f02",
   "metadata": {},
   "source": [
    "2. Create input sequences of length 40 → predict 41st; vectorize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18de46ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 439438\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "seq_length = 40\n",
    "step = 1\n",
    "sequences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - seq_length, step):\n",
    "    sequences.append(text[i: i + seq_length])\n",
    "    next_chars.append(text[i + seq_length])\n",
    "print(\"Number of sequences:\", len(sequences))\n",
    "\n",
    "X = np.zeros((len(sequences), seq_length, vocab_size), dtype=np.bool_)\n",
    "y = np.zeros(len(sequences), dtype=np.int32)\n",
    "for i, seq in enumerate(sequences):\n",
    "    for t, ch in enumerate(seq):\n",
    "        X[i, t, char_to_idx[ch]] = 1\n",
    "    y[i] = char_to_idx[next_chars[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74ff4e",
   "metadata": {},
   "source": [
    "3. Create training sequence dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "575bfd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(64, 40, 82), dtype=tf.bool, name=None), TensorSpec(shape=(64,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "ds = ds.shuffle(buffer_size).batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(ds.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076fa040",
   "metadata": {},
   "source": [
    "4. Build RNN model using SimpleRNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c940c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyjain/Documents/CODING/MCA-Assignments/Trimester-5/nndl/.venv/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,074</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m86,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m)             │        \u001b[38;5;34m21,074\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">239,186</span> (934.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m239,186\u001b[0m (934.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">239,186</span> (934.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m239,186\u001b[0m (934.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    SimpleRNN(256, return_sequences=True, input_shape=(seq_length, vocab_size)),\n",
    "    SimpleRNN(256),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d09aaa",
   "metadata": {},
   "source": [
    "5. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d79f917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m6866/6866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 16ms/step - loss: 2.6042\n",
      "Epoch 2/10\n",
      "\u001b[1m6866/6866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 15ms/step - loss: 2.2146\n",
      "Epoch 3/10\n",
      "\u001b[1m6866/6866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 15ms/step - loss: 2.0935\n",
      "Epoch 4/10\n",
      "\u001b[1m6866/6866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 15ms/step - loss: 2.0319\n",
      "Epoch 5/10\n",
      "\u001b[1m6866/6866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 15ms/step - loss: 1.9823\n",
      "Epoch 6/10\n",
      "\u001b[1m6866/6866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 15ms/step - loss: 1.9434\n",
      "Epoch 7/10\n",
      "\u001b[1m6866/6866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 16ms/step - loss: 2.1353\n",
      "Epoch 8/10\n",
      "\u001b[1m6866/6866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 16ms/step - loss: 2.1016\n",
      "Epoch 9/10\n",
      "\u001b[1m6866/6866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 16ms/step - loss: 2.0585\n",
      "Epoch 10/10\n",
      "\u001b[1m6866/6866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 16ms/step - loss: 2.0323\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit(ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64312d16",
   "metadata": {},
   "source": [
    "6. Write text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee1a9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_with_temperature(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    if temperature <= 0:\n",
    "        return np.argmax(preds)\n",
    "    preds = np.log(preds + 1e-9) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    probs = exp_preds / np.sum(exp_preds)\n",
    "    return np.random.choice(len(probs), p=probs)\n",
    "\n",
    "def generate_text(model, seed, length=400, temperature=1.0):\n",
    "    generated = seed\n",
    "    seq = seed[-seq_length:]\n",
    "    for _ in range(length):\n",
    "        x = np.zeros((1, seq_length, vocab_size), dtype=np.bool_)\n",
    "        for t, ch in enumerate(seq):\n",
    "            if ch in char_to_idx:\n",
    "                x[0, t, char_to_idx[ch]] = 1\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_idx = sample_with_temperature(preds, temperature)\n",
    "        next_char = idx_to_char[next_idx]\n",
    "        generated += next_char\n",
    "        seq = seq[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffdbf0",
   "metadata": {},
   "source": [
    "7. Generate new text and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7975fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: M r. and Mrs. Dursley, of number four, P\n",
      "\n",
      "Temperature 0.2\n",
      " M r. and Mrs. Dursley, of number four, Powed a so was in in and seell and so and stust and stear in the stus the so was his the me the stell in and his hind the gor gor the dich was the clid wing hing stear the deaked the so the clid stee the and steed in in in and his the dook the door the whing the sick the sill the dor the dooked the d\n",
      "\n",
      "Temperature 1.0\n",
      " M r. and Mrs. Dursley, of number four, Peshy;.”\n",
      "\n",
      "“No E!” you Trear it Hagrid, uld stumchns nighing Mree sruming the reamed hade nolchered, yome you facked, with clan sild at in’t bot\n",
      "\n",
      "Hinderill,”\n",
      "\n",
      "Hl yicer niked whood fein to Murstere on it migh his he knyand a mill senn cosndleds chere up hew and gemconing, es Prut,” sim at the mooald at\n",
      "\n",
      "Temperature 1.2\n",
      " M r. and Mrs. Dursley, of number four, Ped, it hine, Harry’le “ as uughed feably; Verytten tall wament wotas;, iuthco araned the sroad exs-les.”\n",
      "\n",
      "Thove; sis, to sroutos renk. M.…HAVask fot; incs, freinit flidese oll’Line:\n",
      "\n",
      "Sor at nir Qugwhoucandsban. Ave, The deenbmiundecele grimes onnpnll fwhanet hilling, to the chpmed in excamp to lild!\n"
     ]
    }
   ],
   "source": [
    "seed = text[:seq_length]\n",
    "print(\"Seed:\", seed)\n",
    "print(\"\\nTemperature 0.2\\n\", generate_text(model, seed, length=300, temperature=0.2))\n",
    "print(\"\\nTemperature 1.0\\n\", generate_text(model, seed, length=300, temperature=1.0))\n",
    "print(\"\\nTemperature 1.2\\n\", generate_text(model, seed, length=300, temperature=1.2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
